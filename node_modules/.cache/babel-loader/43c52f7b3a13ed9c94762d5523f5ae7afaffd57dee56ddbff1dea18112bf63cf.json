{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../resource.mjs\";\nimport * as Core from \"../core.mjs\";\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   *\n   * @example\n   * ```ts\n   * const createEmbeddingResponse =\n   *   await client.embeddings.create({\n   *     input: 'The quick brown fox jumped over the lazy dog',\n   *     model: 'text-embedding-3-small',\n   *   });\n   * ```\n   */\n  create(body, options) {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format = hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n    if (hasUserProvidedEncodingFormat) {\n      Core.debug('Request', 'User defined encoding_format:', body.encoding_format);\n    }\n    const response = this._client.post('/embeddings', {\n      body: {\n        ...body,\n        encoding_format: encoding_format\n      },\n      ...options\n    });\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    Core.debug('response', 'Decoding base64 embeddings to float32 array');\n    return response._thenUnwrap(response => {\n      if (response && response.data) {\n        response.data.forEach(embeddingBase64Obj => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding;\n          embeddingBase64Obj.embedding = Core.toFloat32Array(embeddingBase64Str);\n        });\n      }\n      return response;\n    });\n  }\n}","map":{"version":3,"names":["APIResource","Core","Embeddings","create","body","options","hasUserProvidedEncodingFormat","encoding_format","debug","response","_client","post","_thenUnwrap","data","forEach","embeddingBase64Obj","embeddingBase64Str","embedding","toFloat32Array"],"sources":["/Users/tato/repo/github/tatoflam/logo-generator-app/node_modules/openai/src/resources/embeddings.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   *\n   * @example\n   * ```ts\n   * const createEmbeddingResponse =\n   *   await client.embeddings.create({\n   *     input: 'The quick brown fox jumped over the lazy dog',\n   *     model: 'text-embedding-3-small',\n   *   });\n   * ```\n   */\n  create(\n    body: EmbeddingCreateParams,\n    options?: Core.RequestOptions<EmbeddingCreateParams>,\n  ): Core.APIPromise<CreateEmbeddingResponse> {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format: EmbeddingCreateParams['encoding_format'] =\n      hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n\n    if (hasUserProvidedEncodingFormat) {\n      Core.debug('Request', 'User defined encoding_format:', body.encoding_format);\n    }\n\n    const response: Core.APIPromise<CreateEmbeddingResponse> = this._client.post('/embeddings', {\n      body: {\n        ...body,\n        encoding_format: encoding_format as EmbeddingCreateParams['encoding_format'],\n      },\n      ...options,\n    });\n\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    Core.debug('response', 'Decoding base64 embeddings to float32 array');\n\n    return (response as Core.APIPromise<CreateEmbeddingResponse>)._thenUnwrap((response) => {\n      if (response && response.data) {\n        response.data.forEach((embeddingBase64Obj) => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding as unknown as string;\n          embeddingBase64Obj.embedding = Core.toFloat32Array(embeddingBase64Str);\n        });\n      }\n\n      return response;\n    });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * all embedding models), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens. In addition to the per-input token limit, all embedding\n   * models enforce a maximum of 300,000 tokens summed across all inputs in a single\n   * request.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\n   * them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n   */\n  user?: string;\n}\n\nexport declare namespace Embeddings {\n  export {\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\n    type Embedding as Embedding,\n    type EmbeddingModel as EmbeddingModel,\n    type EmbeddingCreateParams as EmbeddingCreateParams,\n  };\n}\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;OACf,KAAKC,IAAI;AAEhB,OAAM,MAAOC,UAAW,SAAQF,WAAW;EACzC;;;;;;;;;;;;EAYAG,MAAMA,CACJC,IAA2B,EAC3BC,OAAoD;IAEpD,MAAMC,6BAA6B,GAAG,CAAC,CAACF,IAAI,CAACG,eAAe;IAC5D;IACA;IACA,IAAIA,eAAe,GACjBD,6BAA6B,GAAGF,IAAI,CAACG,eAAe,GAAG,QAAQ;IAEjE,IAAID,6BAA6B,EAAE;MACjCL,IAAI,CAACO,KAAK,CAAC,SAAS,EAAE,+BAA+B,EAAEJ,IAAI,CAACG,eAAe,CAAC;;IAG9E,MAAME,QAAQ,GAA6C,IAAI,CAACC,OAAO,CAACC,IAAI,CAAC,aAAa,EAAE;MAC1FP,IAAI,EAAE;QACJ,GAAGA,IAAI;QACPG,eAAe,EAAEA;OAClB;MACD,GAAGF;KACJ,CAAC;IAEF;IACA,IAAIC,6BAA6B,EAAE;MACjC,OAAOG,QAAQ;;IAGjB;IACA;IACA;IACA;IACAR,IAAI,CAACO,KAAK,CAAC,UAAU,EAAE,6CAA6C,CAAC;IAErE,OAAQC,QAAqD,CAACG,WAAW,CAAEH,QAAQ,IAAI;MACrF,IAAIA,QAAQ,IAAIA,QAAQ,CAACI,IAAI,EAAE;QAC7BJ,QAAQ,CAACI,IAAI,CAACC,OAAO,CAAEC,kBAAkB,IAAI;UAC3C,MAAMC,kBAAkB,GAAGD,kBAAkB,CAACE,SAA8B;UAC5EF,kBAAkB,CAACE,SAAS,GAAGhB,IAAI,CAACiB,cAAc,CAACF,kBAAkB,CAAC;QACxE,CAAC,CAAC;;MAGJ,OAAOP,QAAQ;IACjB,CAAC,CAAC;EACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}